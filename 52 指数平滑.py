#-*- coding: utf-8 -*-

########  æœ¬æ–‡ä»¶å®ç°ç§»åŠ¨å¹³å‡ï¼ŒåŒ…æ‹¬
#   Part1 ä¸€æ¬¡æŒ‡æ•°å¹³æ»‘/ç®€å•æŒ‡æ•°å¹³æ»‘
#   Part2 äºŒæ¬¡æŒ‡æ•°å¹³æ»‘
#   Part3 ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.optimize as spo

from common import displayRegressionMetrics


# 1ã€è¯»å–æ•°æ®é›†
filename = 'æ—¶é—´åºåˆ—.xls'
sheet = 'é¤å…é”€é‡'
df = pd.read_excel(filename, sheet)
print(df.columns.tolist())

df.set_index('æ—¥æœŸ', inplace=True)
ts = df['é”€é‡']

# 2ã€å¯è§†åŒ–
ts.plot(title='é¤å…é”€é‡')
plt.show()

######################################################################
########  Part1ã€ä¸€æ¬¡æŒ‡æ•°å¹³æ»‘ Simple Exponential Smoothing
######################################################################
# SimpleExpSmoothing(endog)
# SimpleExpSmoothing.fit(smoothing_level=None, 
                # optimized=True,   é»˜è®¤ä¼˜åŒ–æœªæŒ‡å®šçš„å‚æ•°
                # start_params=None, 
                # initial_level=None, æŒ‡å®šé¢„æµ‹çš„åˆå§‹å€¼
                # use_brute=True)     é»˜è®¤ä½¿ç”¨æš´åŠ›å¯»æ‰¾åˆå§‹å€¼

from statsmodels.tsa.holtwinters import SimpleExpSmoothing

# 3.è®­ç»ƒæ¨¡å‹

# #######æŒ‡å®šå›ºå®šå¹³æ»‘ç³»æ•°
alpha = 0.8
mdl = SimpleExpSmoothing(ts)
results = mdl.fit(smoothing_level=alpha,
            optimized=False)
print(results.summary())    #æ‰“å°æ¨¡å‹ä¿¡æ¯

print('æ¨¡å‹å‚æ•°ï¼š\n', results.params)   #è¿”å›å‚æ•°å­—å…¸

# 4.æ¨¡å‹è¯„ä¼°
# 1ï¼‰æŸ¥çœ‹è¯„ä¼°æŒ‡æ•°
print('AIC=', results.aic)
print('AICC=', results.aicc)
print('BIC=', results.bic)
# print('SSE=', results.sse)
# resid = results.resid     # æ®‹å·®resid = ts - y_pred
y_pred = results.fittedvalues   # é¢„æµ‹å†å²å€¼
y_true = ts[y_pred.index]

displayRegressionMetrics(y_true, y_pred)

# 2ï¼‰å¯è§†åŒ–å›¾å½¢ï¼šå¯¹æ¯”
plt.plot(range(len(y_pred)), y_pred, 'b', label='ä¸€æ¬¡æŒ‡æ•°å¹³æ»‘')
plt.plot(range(len(y_true)), y_true, 'g', label='å®é™…å€¼')

plt.legend(loc='upper right')
title = 'Holtçº¿æ€§è¶‹åŠ¿(alpha={})'.format(alpha)
plt.title(title)
plt.show()

# 5.è‡ªè¡Œé€‰å–æœ€ä¼˜å¹³æ»‘ç³»æ•°
mdl = SimpleExpSmoothing(ts)
results = mdl.fit()         #é»˜è®¤optimized=True
print(results.summary())    #æ‰“å°æ¨¡å‹ä¿¡æ¯

print('æœ€ä¼˜alpha=', results.params['smoothing_level'])
# å¯æƒœå·²ç»å–åˆ°äº†è¾¹ç•Œå€¼ï¼Œä¸åˆé€‚

# å…¶ä½™åŒä¸Šï¼šæŒ‡æ ‡ã€å¯è§†åŒ–
y_pred = results.fittedvalues   # é¢„æµ‹å†å²å€¼
y_true = ts[y_pred.index]
displayRegressionMetrics(y_true, y_pred)

# 6.åº”ç”¨æ¨¡å‹
# 1ï¼‰é¢„æµ‹å†å²å€¼ï¼Œendé»˜è®¤ä¸ºæœ€åæ—¥æœŸ
# å¦‚æœæŒ‡å®šåˆ°æœªæ¥çš„æ—¶æœŸï¼Œå°†ä¼šè¿›è¡Œæ»šåŠ¨é¢„æµ‹
pred = results.predict(start='2015-02-01', end='2015-02-10')
print(pred)

# 2ï¼‰è¿›è¡Œæ»šåŠ¨é¢„æµ‹ï¼Œé¢„æµ‹æœªæ¥å‡ ä¸ªå€¼
pred = results.forecast(5)
print(pred)
# ç”±äºé‡‡ç”¨æ»šåŠ¨é¢„æµ‹ï¼Œè¶Šè¿œè¶Šä¸å‡†ç¡®

# 3)ä¿å­˜æ¨¡å‹
fname = 'out.pkl'
results.save(fname)

# 4ï¼‰åŠ è½½æ¨¡å‹
from statsmodels.iolib.smpickle import load_pickle
results = load_pickle(fname)

# 5)åº”ç”¨æ¨¡å‹
print(results.params)
pred = results.forecast(3)
print(pred)

######################################################################
########  Part2ã€äºŒæ¬¡æŒ‡æ•°å¹³æ»‘ Double Exponential Smoothing
######################################################################
# Brown's Linear Exponential Smoothing

def double_exponential_smoothing(ts, alpha=0.8, isPlot=True):
    """
    å¸ƒæœ—çº¿æ€§è¶‹åŠ¿æ¨¡å‹ï¼ˆäºŒæ¬¡æŒ‡æ•°å¹³æ»‘ï¼‰
    """
    S1 = ts.ewm(alpha=alpha).mean()
    S2 = S1.ewm(alpha=alpha).mean()

    at = 2*S1 - S2
    bt = alpha*(S1 - S2)/(1-alpha)

    yhat = at + bt
    # ret = yhat[-1]
    pred = yhat.shift(1)
    y_pred = pred.dropna()
    y_true = ts[pred.index]

    # è®¡ç®—è¯¯å·®ç‡
    mape = (np.abs(y_pred - y_true)/y_true).mean()

    if isPlot:
        # å¯è§†åŒ–å›¾å½¢
        plt.plot(range(len(y_pred)), y_pred, 'b', label='æŒ‡æ•°å¹³æ»‘')
        plt.plot(range(len(y_true)), y_true, 'g', label='å®é™…å€¼')
        
        plt.legend(loc='upper right')
        title = 'äºŒæ¬¡æŒ‡æ•°å¹³æ»‘(alpha={})'.format(alpha)
        plt.title(title)
        plt.show()

    return mape

alpha = 0.5
mape = double_exponential_smoothing(ts, alpha)
print('MAPE={:.4%}'.format(mape))

# 5.å¯»æ‰¾æœ€ä¼˜alpha
import scipy.optimize as spo


def optimizeDES(ts, alpha):
    """
    äºŒæ¬¡æŒ‡æ•°å¹³æ»‘ï¼Œå¯»æ‰¾æœ€ä¼˜å¹³æ»‘ç³»æ•°alpha
    """

    # å®šä¹‰è¯¯å·®å‡½æ•°ï¼ˆå‚æ•°:å¹³æ»‘ç³»æ•°ï¼Œå…¶å®ƒå‚æ•°:å…ƒç»„ï¼‰
    def error(alpha, *var):
        ts = var[0]
        S1 = ts.ewm(alpha=alpha).mean()
        S2 = S1.ewm(alpha=alpha).mean()

        at = 2*S1 - S2
        bt = alpha*(S1 - S2)/(1-alpha)

        yhat = at + bt
        # ret = yhat[-1]
        pred = yhat.shift(1)
        y_pred = pred.dropna()
        y_true = ts[y_pred.index]

        mse = metrics.mean_squared_error(y_true, y_pred)
        return mse

    # çº¦æŸæ¡ä»¶
    bnds = [(0,1)]   #alphaå–å€¼èŒƒå›´

    # ä¼˜åŒ–
    optResult = spo.minimize(error, alpha, args=(ts,),
                method='SLSQP',
                bounds=bnds,
                # options={'maxiter':1000,'disp':True}
                )
    assert(optResult['success'])
    # print(optResult)

    return optResult['x']   #åªè¿”å›æœ€ä¼˜å‚æ•°

alpha = 0.5
best_alpha = optimizeDES(ts, alpha)
print('æœ€ä¼˜å‚æ•°ï¼š', best_alpha)

mape = double_exponential_smoothing(ts, best_alpha)
print('MAPE={:.4%}'.format(mape))

######################################################################
########  Part3ã€ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘ Triple Exponential Smoothing
######################################################################


def Triple_exponential_smoothing(ts, alpha=0.8, isPlot=True):
    """
    ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘ï¼Œé€‚ç”¨äºäºŒæ¬¡æ›²çº¿è¶‹åŠ¿
    """
    S1 = ts.ewm(alpha=alpha).mean()
    S2 = S1.ewm(alpha=alpha).mean()
    S3 = S2.ewm(alpha=alpha).mean()

    at = 3*S1 - 3*S2 + S3
    bt = alpha*((6-5*alpha)*S1 - 2*(5-4*alpha)*S2 + (4-3*alpha)*S3)/(2*((1-alpha)**2))
    ct = (alpha**2)*(S1 - 2*S2 + S3)/(2*((1-alpha)**2))

    yhat = at + bt + ct
    # ret = yhat[-1]
    pred = yhat.shift(1)
    y_pred = pred.dropna()
    y_true = ts[pred.index]

    # è®¡ç®—è¯¯å·®ç‡
    mape = (np.abs(y_pred - y_true)/y_true).mean()

    if isPlot:
        # å¯è§†åŒ–å›¾å½¢
        plt.plot(range(len(y_pred)), y_pred, 'b', label='æŒ‡æ•°å¹³æ»‘')
        plt.plot(range(len(y_true)), y_true, 'g', label='å®é™…å€¼')
        
        plt.legend(loc='upper right')
        title = 'ä¸‰æ¬¡æŒ‡æ•°å¹³æ»‘(alpha={})'.format(alpha)
        plt.title(title)
        plt.show()

    return mape

alpha = 0.8
mape = Triple_exponential_smoothing(ts, alpha)
print('MAPE={:.4%}'.format(mape))


def optimizeTES(ts, alpha):
    """
    äºŒæ¬¡æŒ‡æ•°å¹³æ»‘ï¼Œå¯»æ‰¾æœ€ä¼˜å¹³æ»‘ç³»æ•°alpha
    """

    # å®šä¹‰è¯¯å·®å‡½æ•°ï¼ˆå‚æ•°:å¹³æ»‘ç³»æ•°ï¼Œå…¶å®ƒå‚æ•°:å…ƒç»„ï¼‰
    def error(alpha, *var):
        ts = var[0]
        S1 = ts.ewm(alpha=alpha).mean()
        S2 = S1.ewm(alpha=alpha).mean()
        S3 = S2.ewm(alpha=alpha).mean()

        at = 3*S1 - 3*S2 + S3
        bt = alpha*((6-5*alpha)*S1 - 2*(5-4*alpha)*S2 + (4-3*alpha)*S3)/(2*((1-alpha)**2))
        ct = (alpha**2)*(S1 - 2*S2 + S3)/(2*((1-alpha)**2))

        yhat = at + bt + ct
        # ret = yhat[-1]
        pred = yhat.shift(1)
        y_pred = pred.dropna()
        y_true = ts[y_pred.index]

        mse = metrics.mean_squared_error(y_true, y_pred)
        return mse

    # çº¦æŸæ¡ä»¶
    bnds = [(0,1)]   #alphaå–å€¼èŒƒå›´

    # ä¼˜åŒ–
    optResult = spo.minimize(error, alpha, args=(ts,),
                method='SLSQP',
                bounds=bnds,
                # options={'maxiter':1000,'disp':True}
                )
    assert(optResult['success'])
    print(optResult)

    return optResult['x']   #åªè¿”å›æœ€ä¼˜å‚æ•°åˆ—è¡¨

alpha = 0.2
best_alpha = optimizeTES(ts, alpha)
print('æœ€ä¼˜å‚æ•°ï¼š', best_alpha)

mape = Triple_exponential_smoothing(ts, best_alpha)
print('MAPE={:.4%}'.format(mape))



# DataFrame.ewm #æŒ‡æ•°åŠ æƒç§»åŠ¨å¹³å‡ï¼Œå³æŒ‡æ•°å¹³æ»‘
    # (com=None, span=None, halflife=None, alpha=None, 
    #           min_periods=0, adjust=True, ignore_na=False, axis=0)
    # com : float, optional
    # Specify decay in terms of center of mass, ğ›¼=1/(1+ğ‘ğ‘œğ‘š), for ğ‘ğ‘œğ‘šâ‰¥0
    # Î±  = 1 / (1 + com), for com â‰¥ 0
    # span : float, optional
    # Specify decay in terms of span, ğ›¼=2/(ğ‘ ğ‘ğ‘ğ‘›+1), for ğ‘ ğ‘ğ‘ğ‘›â‰¥1
    # halflife : float, optional
    # Specify decay in terms of half-life, ğ›¼=1âˆ’ğ‘’ğ‘¥ğ‘(ğ‘™ğ‘œğ‘”(0.5)/â„ğ‘ğ‘™ğ‘“ğ‘™ğ‘–ğ‘“ğ‘’), for â„ğ‘ğ‘™ğ‘“ğ‘™ğ‘–ğ‘“ğ‘’>0
    # alpha : float, optionalã€‚å¹³æ»‘å› å­0<ğ›¼â‰¤1
    # min_periods : int, default 0
    # Minimum number of observations in window required to have a value (otherwise result is NA).
    # adjust : bool, default True
    #   å½“ä¸ºFalseæ—¶ï¼Œå‡å®šå†å²æ•°æ®æ˜¯æ— é™çš„ï¼Œç®€åŒ–è®¡ç®—å…¬å¼
    #   å½“ä¸ºTrueæ—¶ï¼Œå‡å®šå†å²æ•°æ®æ˜¯æœ‰é™çš„ï¼Œè®¡ç®—å…¬å¼æ¯”è¾ƒå¤æ‚
    # ignore_na : bool, default Falseã€‚è®¡ç®—æƒé‡æ—¶ï¼Œæ˜¯å¦å¿½ç•¥ç¼ºå¤±å€¼ã€‚
